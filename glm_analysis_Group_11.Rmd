---
title: "Group_11_Analysis"
author: "Group11"
date: "2023-03-09"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction
Based on the Coffee Quality Database (CQD), this report aims to investigate the features of coffee that influence its quality.

# Step 1: Exploratory Data Analysis
Load the required packages and read the data.

```{r Loading, message=FALSE, warning=FALSE}
library(tidyr)
library(ggplot2)
library(skimr)
library(dplyr)
library(gridExtra)
library(GGally)
library(gmodels)
library(stats)
library(sjPlot)
library(jtools)
library(MASS)
library(knitr)

coffee <- read.csv('https://raw.githubusercontent.com/rrachelxi/DAS-Group-11/main/dataset11.csv')
```

```{r skim data}
coffee <- coffee %>%
  # Harvested, country_of_origin and Qualityclass are turned into factor
  mutate(
    harvested = as.factor(harvested),
    country_of_origin = as.factor(country_of_origin), 
    Qualityclass = as.factor(Qualityclass))
```
\newpage
```{r skim coffee}
# First skim of the dataset
skim_without_charts(coffee) %>%
  summary()

skim_without_charts(coffee) %>%
  yank("numeric") %>%
  kable(caption = '\\label{tab:c1} The numeric variable of the coffee data.', digits = 2)

skim_without_charts(coffee) %>%
  yank("factor") %>%
  kable(caption = '\\label{tab:c2} The vector variable of the coffee data.', digits = 2)
```

From Table 1, there are 191 missing values in altitude_mean_meters, 56 missing values in harvested and 1 missing value in country_of_origin. Since altitude_mean_meters is a continuous variable and the amount of missing values is quite large, these missing values are replaced by the mean value. As for the harvested and country_of_origin, these missing values are deleted because of the small volumes. 

```{r deal with missing values}
# The mean value for altitude_mean_meters is calculated
mean_altitude <- mean(coffee$altitude_mean_meters,na.rm = TRUE)

coffee_m <- coffee %>%
  # Missing values are replaced in altitude_mean_meters by its mean value
  mutate(
    altitude_mean_meters = replace_na(altitude_mean_meters, mean_altitude)) %>% 
  
  # Missing values are dropped in country_of_origin and harvested
  filter(
    !is.na(country_of_origin) & 
    !is.na(harvested))
```

```{r skim coffee_m}
# data is skimmed after dropping missing values
skim_without_charts(coffee_m) %>%
  summary()

skim_without_charts(coffee_m) %>%
  yank("numeric") %>%
  kable(caption = '\\label{tab:m1} The numeric variable of the coffee_m data.', digits = 2)
```
\newpage
```{r skim coffee_m continue}
skim_without_charts(coffee_m) %>%
  yank("factor") %>%
  kable(caption = '\\label{tab:m2} The vector variable of the coffee_m data.', digits = 2)
```

The dataset is now with no missing value. Next, a pair plot is drawn to visualize data.

```{r pair plot of coffee_m, message=FALSE, warning=FALSE, fig.height = 10, fig.width = 14, fit.align = "center", fig.pos='h',  fig.cap = "\\label{fig:pp1} Pair plot of numeric variables and Qualityclass."}
# A pair plot is drawn
ggpairs(coffee_m[,c(-1,-7)], 
        aes(color=Qualityclass,alpha=0.2), 
        title = "Distribution between variables")
```

As several possible outliers are presented in figure 1, scatter plots are drawn to show outliers more clearly.

```{r scatter plot aroma acidity, fig.cap = "\\label{fig:sp1} Scatter plot of aroma and acidity."}
# A scatter plot for aroma and acidity is drawn 
ggplot(coffee_m,aes(x=aroma,y=acidity,color=Qualityclass)) +
  geom_point() +
  geom_jitter(width = 0.2, height = 0.2) +
  labs(x = "Aroma grade (ranging from 0-10)", 
       y = "Acidity grade (ranging from 0-10)",
       title = "Aroma grade and acidity grade for coffee quality")
```

\newpage
```{r scatter plot altitude_mean_meters, fig.cap = "\\label{fig:sp2} Scatter plot of altitude_mean_meters."}
# A scatter plot for altitude_mean_meters is drawn 
ggplot(coffee_m,aes(x=Qualityclass,y=altitude_mean_meters,color=Qualityclass)) +
  geom_point() +
  geom_jitter(width = 0.2, height = 0.2) +
  labs(x = "Quality Class", 
       y = "Mean altitude of the growers farm (in metres)",
       title = "Mean altitude of the growers group by coffee quality") +
  theme(legend.position = 'none')
```

It can be seen from Figure 1, 2 and 3 that there are many outilers in aroma, acidity and altitude_mean_meters. At the mean time, it can also be noticed that good-quality coffee tend to have a higher level of acidity and aroma, comparing with the poor-quality coffee. 

```{r drop outliers}
# Outlies in aroma, acidity and altitude_mean_meters are dropped from the dataset
coffee_w <- coffee_m %>%
  filter(
    aroma > 6 & 
    acidity > 6 & 
    altitude_mean_meters < 100000)
```
\newpage
```{r skim coffee_w}
# The dataset is skimmed after dropping outliers
skim_without_charts(coffee_w) %>%
  summary()

skim_without_charts(coffee_w) %>%
  yank("numeric") %>%
  kable(caption = '\\label{tab:w1} The numeric variable of the coffee_w data.', digits = 2)

skim_without_charts(coffee_w) %>%
  yank("factor") %>%
  kable(caption = '\\label{tab:w2} The vector variable of the coffee_w data.', digits = 2)
```
\newpage
```{r pair plot of coffee_w, fig.height = 10, fig.width = 14, fit.align = "center", fig.pos='h', fig.cap = "\\label{fig:pp2} Pair plot of numeric variables and Qualityclass (without outliers).", message=FALSE, warning=FALSE}
# a pair plot without outliers is drawn to visualize data
ggpairs(coffee_w[c(-1,-7)], 
        aes(color=Qualityclass,alpha=0.2), 
        title = "Distribution between variables(without outliers)")
```

From Figure 4, there is a relatively strong correlation between aroma and flavor (correlation: 0.770), similar to acidity and aroma (correlation: 0.643). And box plots of aroma, flavor and acidity show significant differences between classes of quality. 
\newpage
```{r barplot of harvested, fig.cap = "\\label{fig:bp1} Bar plot of quality class by harvested year."}
# A bar plot to visualize the distribution of harvested and Qualityclass
ggplot(coffee_w, aes(x=harvested, y= after_stat(prop), group=Qualityclass, fill=Qualityclass )) +
  geom_bar(position = "dodge") +
  labs(x = "Year the batch was harvested",
       y = "Proportion",
       title = "Proportions of quality class by year the batch was harvested")
```

From Figure 5, the batch of the year 2012 has the highest proportion of good-quality coffee, with the batch of the year 2014 following behind. And the situation is the same for poor-quality coffee.
\newpage
```{r barplot of country, fig.cap = "\\label{fig:bp2} Barplot of quality class by country of origin."}
# A bar plot to visualize the distribution of country_of_origin and Qualityclass
ggplot(coffee_w, aes(x=country_of_origin, group=Qualityclass )) +
  geom_bar(aes(y=after_stat(prop), fill = Qualityclass),  position = "dodge") +
  labs(x = "Country of origin",
       y = "Proportion",
       title = "Proportions of quality class by country of origin") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) 
```

From Figure 6, Mexico has the highest proportion of poor-quality coffee while Colombia has the highest proportion of good-quality coffee.

\newpage
# Step 2: Statistical Modelling

A full general linear model is built and feature selection is conducted stepwise by AIC.

```{r feature selection}
# A full general linear model is built
model_full <- glm(
  Qualityclass ~ 
               aroma + 
               flavor +
               acidity +
               category_two_defects +
               altitude_mean_meters +
               harvested +
               country_of_origin,
  data = coffee_w,
  family = binomial(link="logit"))

# Stepwise by AIC
model_step<-model_full %>%
  stepAIC(trace=TRUE)
```

Based on the AIC table, the model with variable of aroma, flavor, acidity, category_two_defects, altitude_mean_meters and country_of_region would be chosen (without harvested).

```{r summary model_step}
# A summary of the model chosen by stepwise selection
summary(model_step)
```

\newpage
```{r model_step accuracy}
# Predict results from model_step are added to the dataset
coffee_step <- coffee_w %>%
  mutate(logodds_poor = predict(model_step),
         probs_poor = fitted(model_step)) %>%
  mutate(odd_poor = exp(logodds_poor),
         class_pred = ifelse(probs_poor>0.5,"Poor","Good"))

# Accuracy for model_step is calculated
sum(coffee_step$class_pred == coffee_step$Qualityclass)/nrow(coffee_step)
```

The p values of aroma, flavor and acidity are smaller than 0.05, which indicates these variables have a significant relationship with the quality class of coffee. Then, a new model called model_1 with these significant coefficients is built.

```{r model with significant coefficients}
# Model with significant coefficients
model_1 <- glm(
  Qualityclass ~ 
               aroma + 
               flavor +
               acidity,
  data = coffee_w,
  family = binomial(link="logit"))
```

```{r summary model_1}
# Summary model_1
summary(model_1)
```

```{r model_1 accuracy}
# Predict results from model_1 are added to the dataset
coffee_1 <- coffee_w %>%
  mutate(logodds_poor = predict(model_1),
         probs_poor = fitted(model_1)) %>%
  mutate(odd_poor = exp(logodds_poor),
         class_pred = ifelse(probs_poor>0.5,"Poor","Good"))

# Accuracy for model_1 is calculated
sum(coffee_1$class_pred == coffee_1$Qualityclass)/nrow(coffee_1)
```

model_1 has slightly higher AIC and less accuracy than model_step, but all coefficients in model_1 are significant, thus model_1 is chosen as the final model. 

```{r Odds (Poor quality), out.width="80%", fig.cap = "\\label{fig:odd} Point estimates and confidence intervals for odds."}
# Plot point estimates and confidence intervals of model_1
plot_model(model_1, show.values = TRUE, 
           title = "Odds (Poor quality)",
           show.p = FALSE, digits=3)
```
From Figure 7, it can be seen that for every 0.1 unit increase in aroma, the probability of being poor coffee becomes 0.012 times that of before. For every 0.1 increase in flavor, the probability of being poor coffee becomes 0.001 times that of before and for every 0.1 unit increase in acidity, the probability of being poor coffee quality becomes 0.037 times that of before.
\newpage
```{r aroma, out.width="65%" , fig.align = "center", fig.cap = "\\label{fig:aroma} Probability of being poor quality by aroma."}
# Possibilities of being poor-quality by aroma in model_1 is visualized 
plot_model(model_1, type="pred", terms="aroma [all]", 
           axis.title = "Probability",
           title = "Probability of being poor quality by aroma")
```
```{r flavor, out.width="65%" , fig.align = "center", fig.cap = "\\label{fig:flavor} Probability of being poor quality by flavor."}
# Possibilities of being poor-quality by flavor in model_1 is visualized 
plot_model(model_1, type="pred", terms="flavor [all]", 
           axis.title = "Probability",
           title = "Probability of being poor quality by flavor")
```
```{r acidity, out.width="65%" , fig.align = "center", fig.cap = "\\label{fig:acidity} Probability of being poor quality by acidity"}
# Possibilities of being poor quality by acidity in model_1 is visualized 
plot_model(model_1, type="pred", terms="acidity [all]", 
           axis.title = "Probability",
           title = "Probability of being poor quality by acidity")
```

From Figures 8,9 and 10, it can be seen that the probability of being poor-quality would decrease with higher levels of aroma, flavor and acidity.

# Step 3: Summary and further task

Summary: Based on these plots above, high values of aroma, flavor and acidity all indicate a low probability of being poor coffee quality. In particular, the flavor has the most significant influence on the quality of coffee. 

Further work:

1. DARA SEPARATION\
Since the dataset did not be separated into the train, valid and test sets, the model may be overfitting. This problem can be alleviated by data splitting. 

2. HIGH CORRELATION\
It can be noticed that there are high correlations between flavor and aroma, acidity and aroma, and acidity and flavor, which may lead to collinearity. Variance Inflation Factor(VIF) can be used to measure multicollinearity further. If it exists, transformation can be considered to make variables less correlated but still maintain their feature. Another method to solve this problem is Principal Component Analysis, which will reduce the dimensions of data by decomposing data into several independent factors. 
